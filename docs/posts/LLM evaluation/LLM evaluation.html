<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.33">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Safouane Chergui">
<meta name="dcterms.date" content="2025-11-19">

<title>Stop Vibe-Checking: Real-World Lessons on LLM Evals ‚Äì Safouane Chergui</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-ea385d0e468b0dd5ea5bf0780b1290d9.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-c1fac2584b48ed01fb6e278e36375074.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Safouane Chergui</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../resume.html"> 
<span class="menu-text">Resume</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/chsafouane"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/safouane-chergui/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://buymeacoffee.com/chsafouane"> <i class="bi bi-cup-straw" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../sitemap.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Stop Vibe-Checking: Real-World Lessons on LLM Evals</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">LLM</div>
                <div class="quarto-category">Agent</div>
                <div class="quarto-category">Evaluation</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Safouane Chergui </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">November 19, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<nav id="TOC" role="doc-toc">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction">Introduction</a></li>
  <li><a href="#pre-lesson" id="toc-pre-lesson">Pre-lesson</a></li>
  <li><a href="#lesson-1-ill-vibe-check-my-app" id="toc-lesson-1-ill-vibe-check-my-app">Lesson 1: I‚Äôll vibe-check my app</a></li>
  <li><a href="#lesson-2-i-dont-have-any-data-to-test-my-application-where-do-i-start" id="toc-lesson-2-i-dont-have-any-data-to-test-my-application-where-do-i-start">Lesson 2: I don‚Äôt have any data to test my application, where do I start ?</a>
  <ul>
  <li><a href="#sub-lesson-1-real-data-is-better-than-synthetic-data" id="toc-sub-lesson-1-real-data-is-better-than-synthetic-data">Sub-lesson 1: Real data is better than synthetic data</a></li>
  <li><a href="#sub-lesson-2-the-bad-way-to-create-synthetic-data" id="toc-sub-lesson-2-the-bad-way-to-create-synthetic-data">Sub-lesson 2: The bad way to create synthetic data</a></li>
  <li><a href="#sub-lesson-3-the-good-way-to-create-synthetic-data" id="toc-sub-lesson-3-the-good-way-to-create-synthetic-data">Sub-lesson 3: The good way to create synthetic data</a></li>
  </ul></li>
  <li><a href="#lesson-3-have-a-systematic-way-to-identify-failure-modes" id="toc-lesson-3-have-a-systematic-way-to-identify-failure-modes">Lesson 3: Have a systematic way to identify failure modes</a>
  <ul>
  <li><a href="#sub-lesson-1-the-three-steps-for-error-analysis" id="toc-sub-lesson-1-the-three-steps-for-error-analysis">Sub-lesson 1: The three steps for error analysis</a>
  <ul>
  <li><a href="#traces-are-king" id="toc-traces-are-king">Traces are king</a></li>
  <li><a href="#open-coding" id="toc-open-coding">Open-coding</a></li>
  <li><a href="#axial-coding" id="toc-axial-coding">Axial coding</a></li>
  <li><a href="#what-comes-next" id="toc-what-comes-next">What comes next ?</a></li>
  <li><a href="#scale-your-evals-in-production" id="toc-scale-your-evals-in-production">Scale your evals in production</a></li>
  </ul></li>
  <li><a href="#sub-lesson-2-clustering-production-queries-didnt-work-for-me" id="toc-sub-lesson-2-clustering-production-queries-didnt-work-for-me">Sub-lesson 2: Clustering production queries didn‚Äôt work for me</a></li>
  </ul></li>
  <li><a href="#lesson-4-off-the-shelf-evals-dont-work-that-well" id="toc-lesson-4-off-the-shelf-evals-dont-work-that-well">Lesson 4: Off-the-shelf evals don‚Äôt work that well</a></li>
  <li><a href="#lesson-5-the-evaluation-interface-matters" id="toc-lesson-5-the-evaluation-interface-matters">Lesson 5: The evaluation interface matters</a></li>
  <li><a href="#final-notes" id="toc-final-notes">Final notes</a></li>
  </ul>
</nav>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Deploying LLM-powered systems in production is the easy part. The hard part? Making sure they‚Äôre actually working.</p>
<p>I‚Äôve been deploying LLM-powered systems in production in many companies and across different industries for almost 3 years now. Each time, I encountered the same critical challenge: <strong>how do you truly evaluate whether your LLM is performing well and not only rely on vibe checks ?</strong></p>
<p>If you‚Äôre struggling to move beyond ‚Äúit looks good to me‚Äù when evaluating your LLM applications, this blog post is for you.</p>
<br><br>
<div data-align="center">
<p><img src="./assets/front_image.jpg" width="80%" style="display: block; margin: 0 auto;"></p>
</div>
<p><br></p>
<p>This blog post contains lessons learnt through hands-on experience. These lessons come mostly from my experience testing what I have learnt in deploying real-life LLM applications, talking with peers, doing courses, and reading blog posts.</p>
<p>Apart from my personal experience, <a href="https://www.linkedin.com/in/hamelhusain/">Hamel Husain</a> &amp; <a href="https://www.linkedin.com/in/shrshnk/">Shreya Shankar</a> both <a href="https://maven.com/parlance-labs/evals">course</a> &amp; blogs on LLM evaluation have been of a great help to me and many of the techniques I discuss here are either directly quoted from their work or highly inspired by it.</p>
<p>Each of the lessons below will tackle a specific part of building and evaluating real LLM applications.</p>
</section>
<section id="pre-lesson" class="level1">
<h1>Pre-lesson</h1>
<p>I can‚Äôt emphasize this enough and even though you‚Äôve probably heard it a million times before, I‚Äôll have to say it: <strong>KNOW YOUR PRODUCT AND YOUR USERS</strong>.</p>
<p>If you don‚Äôt know your users and your product well, you won‚Äôt be able to understand the different ways they‚Äôll interact with your system, the different types of queries they‚Äôll make, and the different ways they can express the same intent. This is going to be a major obstacle whether you want to create synthetic data, to create evaluation metrics, or to interpret the results of your evaluations.</p>
<p>Now that this is said, let‚Äôs dive into the lessons!</p>
</section>
<section id="lesson-1-ill-vibe-check-my-app" class="level1">
<h1>Lesson 1: I‚Äôll vibe-check my app</h1>
<p>Here‚Äôs a common scenario I‚Äôve encountered many times: a company builds a RAG system over their product documentation, and naturally wants to evaluate and improve it. But there‚Äôs a pattern I keep seeing so often, companies expecting AI to ‚Äújust work‚Äù out of the box.</p>
<p>This expectation shows up most clearly in evaluation practices. Companies often use ‚Äúvibe checks‚Äù by manually asking a dozen of questions and eyeballing whether the system answers seem reasonable.</p>
<p>This is a terrible way to evaluate your LLM applications for multiple reasons:</p>
<ul>
<li><p>The queries you‚Äôre going to ask are biased towards what you think the system should be able to do or towards a specific range of queries that you expect the final user to enter. You will likely miss most of the cases and failure modes that you didn‚Äôt think about. From first-hand experience, the users usually will surprise you with the way they write their queries and the types of queries they will enter. You should expect them to write them as if they are in a rush üòÖ</p></li>
<li><p>Not having evaluated your app in a systematic and/or scalable way will lead to have to deal with ‚Äúwhack-a-mole‚Äù situation (as Hamel so beautifully puts it) where you fix one by changing some prompt only to have another one pop up somewhere else. This will lead to frustration from your stakeholders, frustration from the team working on the app, and maybe even to a a lack of trust in LLMs whithin your organization.</p></li>
</ul>
<div data-align="center">
<p><img src="https://media4.giphy.com/media/v1.Y2lkPTc5MGI3NjExdm55dDYxNHd5eHdmYzlnZmJnMTg4OHRvb2x4ZWQ4bHVnZzQ2am9waiZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/ebITvSXYKNvRm/giphy.gif" width="20%" style="display: block; margin: 0 auto;"></p>
</div>
<p><br></p>
</section>
<section id="lesson-2-i-dont-have-any-data-to-test-my-application-where-do-i-start" class="level1">
<h1>Lesson 2: I don‚Äôt have any data to test my application, where do I start ?</h1>
<p>Once you develop your LLM-powered app, you are faced with <strong>‚ÄúWhich comes first, the chicken or the egg?‚Äù</strong> dilemma:</p>
<ul>
<li>You don‚Äôt have real user queries data because you haven‚Äôt deployed you app yet</li>
<li>You can‚Äôt deploy your app yet because you haven‚Äôt tested it with real user queries yet</li>
</ul>
<section id="sub-lesson-1-real-data-is-better-than-synthetic-data" class="level2">
<h2 class="anchored" data-anchor-id="sub-lesson-1-real-data-is-better-than-synthetic-data">Sub-lesson 1: Real data is better than synthetic data</h2>
<p>You can almost always get some pseudo-real data. If you can‚Äôt have access to some beta users, ask your teammates to test the system. They will have very probably some biases of their own, but at least you will get some data that is not completely synthetic and that has different characteristics because it‚Äôs coming from different people.</p>
</section>
<section id="sub-lesson-2-the-bad-way-to-create-synthetic-data" class="level2">
<h2 class="anchored" data-anchor-id="sub-lesson-2-the-bad-way-to-create-synthetic-data">Sub-lesson 2: The bad way to create synthetic data</h2>
<p>Real data is always better than synthetic data. But hey, if you really can‚Äôt have some real data, then synthetic data is the way to go.</p>
<p>The mistake most people do when creating synthetic data is to ask an LLM to generate queries that are similar to what they expect the users to enter. This is a also a bad idea as the generated queries will be biased towards what you think the users will enter and will likely miss many failure modes. Most importantly, the generated queries will likely be ‚Äútoo good‚Äù and not representative of real user queries (messy, mispellings, incomplete‚Ä¶).</p>
<p>I‚Äôve trained a retriever in the past on synthetic data generated this way. While the performance on synthetic-queries-like was really good, the performance on real user queries was really bad. The gap between synthetic data and real user data was just too big.</p>
</section>
<section id="sub-lesson-3-the-good-way-to-create-synthetic-data" class="level2">
<h2 class="anchored" data-anchor-id="sub-lesson-3-the-good-way-to-create-synthetic-data">Sub-lesson 3: The good way to create synthetic data</h2>
<ul>
<li><p><em>Think of dimensions of variability of user queries:</em> An approach that I have learnt from Hamel Husain &amp; Shreya Shankar is to first think about the different dimensions of variability in user queries for your specific application. For example, if you‚Äôre building a RAG over a technical product documentation, you can think about several dimensions of variability, such as:</p></li>
<li><p>User type (user, admin, developer, etc.)</p></li>
<li><p>Intent (seeking information, troubleshooting, feature requests, etc.)</p></li>
<li><p>User expertise level (beginner, intermediate, expert, etc.)</p></li>
<li><p>Query length (short queries, long queries, etc.)</p></li>
<li><p>Query complexity (simple queries, complex queries with multiple sub-questions, etc.)</p></li>
<li><p>Query style (formal, informal, typos, etc.)</p></li>
<li><p>etc.</p></li>
</ul>
<p>As a query always depends on the context of the application and the persona of the users (a wink üòâ to the pre-lesson above), a dimension should be really specific to your application and not some general dimensions that someone else has used in another context.</p>
<p>Then, for each dimension, you can brainstorm different values that the dimension can take (or delegate the task of brainstorming values of some dimensions to an LLM). For example, for the ‚Äúuser expertise level‚Äù dimension, you can have the values: ‚Äúbeginner‚Äù, ‚Äúintermediate‚Äù, ‚Äúexpert‚Äù as shown above.</p>
<p>Once the list of dimensions and their possible values is ready, you can start combining them to create tuples that will represent different synthetic queries.</p>
<p>Here are some examples of tuples representing combinations of the dimensions mentioned above.</p>
<pre><code>("end_user", "troubleshoot", "beginner", "short", "simple", "typos")
("developer", "integration_info", "expert", "long", "complex", "formal")
("admin", "permissions_help", "intermediate", "short", "simple", "informal")
("end_user", "feature_discovery", "beginner", "short", "simple", "incomplete")
("support_engineer", "root_cause_analysis", "expert", "long", "complex", "dense")
("end_user", "account_status", "beginner", "short", "simple", "mixed_case")
("developer", "performance_optimization", "expert", "medium", "complex", "typos")
("admin", "audit_logging", "intermediate", "medium", "moderate", "formal")
("end_user", "error_meaning", "beginner", "short", "simple", "abbreviations")</code></pre>
<p>Each tuple becomes a prompt seed you can use to generate multiple queries from üöÄ</p>
<p>And here you have it, asystematic way to create synthetic data that covers a wide range of possible user queries for your specific application</p>
</section>
</section>
<section id="lesson-3-have-a-systematic-way-to-identify-failure-modes" class="level1">
<h1>Lesson 3: Have a systematic way to identify failure modes</h1>
<p>When you start evaluating your LLM applications, you need to have a systematic way to identify failure modes. Not having a systematic way to identify failure modes will lead you to the same ‚Äúwhack-a-mole‚Äù situation mentioned earlier where you fix one failure mode only to have another one pop up somewhere else.</p>
<p>You can identify failure modes using synthetic data (created as explained in Lesson 2) or real user queries (if you have access to them) even before deploying your app in production.</p>
<section id="sub-lesson-1-the-three-steps-for-error-analysis" class="level2">
<h2 class="anchored" data-anchor-id="sub-lesson-1-the-three-steps-for-error-analysis">Sub-lesson 1: The three steps for error analysis</h2>
<p>In short, the steps are: - Generate your system‚Äôs anwsers for the queries that you have (real or synthetic). Gather the traces of the execution for each query. - Open-coding: Note down the first failure that appears in the trace for each query (if present) - Axial coding: Cluster the failures into families of failure modes.</p>
<p>This three steps are the key to a successful error analysis. Since I‚Äôve discovered this approach in Hamel &amp; Shreya‚Äôs course, it has become my go-to approach for identifying failure modes in LLM applications in a systematic way.</p>
<section id="traces-are-king" class="level3">
<h3 class="anchored" data-anchor-id="traces-are-king">Traces are king</h3>
<p>A trace is a detailed log of the execution of your LLM application for a query. It includes all the intermediate steps, LLM calls, tool calls, and final output.</p>
<p>Well, now that you have a set of user queries (either real or synthetic), input each query through your LLM application and generate the whole trace of the execution. The trace should include all the intermediate steps, LLM calls, tool calls, and final output.</p>
<p>You should go through a good number of queries to cover the diversity of your queries (usually around a 100 but really depends on the complexity of your application and the diversity of your user queries, could be more or could be less than a 100).</p>
</section>
<section id="open-coding" class="level3">
<h3 class="anchored" data-anchor-id="open-coding">Open-coding</h3>
<p>Once you have the traces, go through each trace one by one and note down the first failure that appears in the trace for each query (if present). The description of the failure should be a bit specific. For example, you can say ‚ÄúDidn‚Äôt call the <code>call_customer_tool</code> even though the customer asked the system to do so‚Äù.</p>
</section>
<section id="axial-coding" class="level3">
<h3 class="anchored" data-anchor-id="axial-coding">Axial coding</h3>
<p>Now that you have annoatated the failures in your dataset, the next step is to put them into clusters of failure modes. You can do: - this manually by going through the list of failures and grouping them into families of failure modes - using an LLM to help you with the clustering. You can provide the LLM with the list of failures and ask it to group them into families of failure modes. This is usually my starting point as it saves a lot of time. Then, I go through the clusters and refine them if needed.</p>
<p>Now, here‚Äôs a diagram that summarizes this 3-step process:</p>
<div class="cell" data-fig-width="6" data-fig-height="5" data-layout-align="center">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<svg width="576" height="480" viewbox="0.00 0.00 212.51 338.92" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 334.92)">
<title>ErrorAnalysis</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-334.92 208.51,-334.92 208.51,4 -4,4"></polygon>
<!-- Start -->
<g id="node1" class="node">
<title>Start</title>
<ellipse fill="#e6f3ff" stroke="#0066cc" stroke-width="2" cx="128.78" cy="-297.26" rx="75.95" ry="33.82"></ellipse>
<text text-anchor="middle" x="128.78" y="-307.16" font-family="Arial" font-size="11.00">Start:</text>
<text text-anchor="middle" x="128.78" y="-293.96" font-family="Arial" font-size="11.00">Collect Queries</text>
<text text-anchor="middle" x="128.78" y="-280.76" font-family="Arial" font-size="11.00">(Real or Synthetic)</text>
</g>
<!-- Step1 -->
<g id="node2" class="node">
<title>Step1</title>
<path fill="#fff9e6" stroke="black" d="M141.36,-226.4C141.36,-226.4 12.21,-226.4 12.21,-226.4 6.21,-226.4 0.21,-220.4 0.21,-214.4 0.21,-214.4 0.21,-191.2 0.21,-191.2 0.21,-185.2 6.21,-179.2 12.21,-179.2 12.21,-179.2 141.36,-179.2 141.36,-179.2 147.36,-179.2 153.36,-185.2 153.36,-191.2 153.36,-191.2 153.36,-214.4 153.36,-214.4 153.36,-220.4 147.36,-226.4 141.36,-226.4"></path>
<text text-anchor="middle" x="76.78" y="-212.7" font-family="Arial" font-size="11.00">1. Generate Traces</text>
<text text-anchor="middle" x="76.78" y="-199.5" font-family="Arial" font-size="11.00">Run queries through system</text>
<text text-anchor="middle" x="76.78" y="-186.3" font-family="Arial" font-size="11.00">Capture execution steps</text>
</g>
<!-- Start&#45;&gt;Step1 -->
<g id="edge1" class="edge">
<title>Start-&gt;Step1</title>
<path fill="none" stroke="black" d="M110.89,-264.44C105.65,-255.12 99.91,-244.92 94.67,-235.6"></path>
<polygon fill="black" stroke="black" points="97.58,-233.63 89.63,-226.63 91.48,-237.06 97.58,-233.63"></polygon>
</g>
<!-- Step2 -->
<g id="node3" class="node">
<title>Step2</title>
<path fill="#e6ffe6" stroke="black" d="M136.61,-132C136.61,-132 46.96,-132 46.96,-132 40.96,-132 34.96,-126 34.96,-120 34.96,-120 34.96,-96.8 34.96,-96.8 34.96,-90.8 40.96,-84.8 46.96,-84.8 46.96,-84.8 136.61,-84.8 136.61,-84.8 142.61,-84.8 148.61,-90.8 148.61,-96.8 148.61,-96.8 148.61,-120 148.61,-120 148.61,-126 142.61,-132 136.61,-132"></path>
<text text-anchor="middle" x="91.78" y="-118.3" font-family="Arial" font-size="11.00">2. Open-Coding</text>
<text text-anchor="middle" x="91.78" y="-105.1" font-family="Arial" font-size="11.00">Annotate first failure</text>
<text text-anchor="middle" x="91.78" y="-91.9" font-family="Arial" font-size="11.00">in each trace</text>
</g>
<!-- Step1&#45;&gt;Step2 -->
<g id="edge2" class="edge">
<title>Step1-&gt;Step2</title>
<path fill="none" stroke="black" d="M80.49,-178.96C82.28,-167.96 84.45,-154.57 86.41,-142.49"></path>
<polygon fill="black" stroke="black" points="89.92,-142.73 88.07,-132.3 83.01,-141.61 89.92,-142.73"></polygon>
</g>
<!-- Step3 -->
<g id="node4" class="node">
<title>Step3</title>
<path fill="#ffe6f0" stroke="black" d="M183.16,-47.4C183.16,-47.4 90.41,-47.4 90.41,-47.4 84.41,-47.4 78.41,-41.4 78.41,-35.4 78.41,-35.4 78.41,-12.2 78.41,-12.2 78.41,-6.2 84.41,-0.2 90.41,-0.2 90.41,-0.2 183.16,-0.2 183.16,-0.2 189.16,-0.2 195.16,-6.2 195.16,-12.2 195.16,-12.2 195.16,-35.4 195.16,-35.4 195.16,-41.4 189.16,-47.4 183.16,-47.4"></path>
<text text-anchor="middle" x="136.78" y="-33.7" font-family="Arial" font-size="11.00">3. Axial Coding</text>
<text text-anchor="middle" x="136.78" y="-20.5" font-family="Arial" font-size="11.00">Cluster failures into</text>
<text text-anchor="middle" x="136.78" y="-7.3" font-family="Arial" font-size="11.00">failure mode families</text>
</g>
<!-- Step2&#45;&gt;Step3 -->
<g id="edge3" class="edge">
<title>Step2-&gt;Step3</title>
<path fill="none" stroke="black" d="M104.32,-84.39C109,-75.8 114.4,-65.88 119.44,-56.64"></path>
<polygon fill="black" stroke="black" points="122.61,-58.14 124.32,-47.69 116.46,-54.79 122.61,-58.14"></polygon>
</g>
<!-- Step3&#45;&gt;Start -->
<g id="edge4" class="edge">
<title>Step3-&gt;Start</title>
<path fill="none" stroke="#0066cc" stroke-width="2" d="M146.53,-47.66C150.76,-58.63 155.31,-72.08 157.78,-84.6 160.85,-100.11 168.25,-202.94 162.78,-226.6 160.56,-236.23 156.81,-246.08 152.6,-255.21"></path>
<polygon fill="#0066cc" stroke="#0066cc" stroke-width="2" points="149.33,-253.92 148.08,-264.44 155.62,-257 149.33,-253.92"></polygon>
<text text-anchor="middle" x="177.54" y="-152.9" font-family="Arial" font-size="9.00">Iterate</text>
</g>
</g>
</svg>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</section>
<section id="what-comes-next" class="level3">
<h3 class="anchored" data-anchor-id="what-comes-next">What comes next ?</h3>
<p><strong>Prioritization:</strong> Now having these clusters of failure modes will help you identify which exact parts of your system are responsible for failures and will help quantify how many failures are due to each failure mode.</p>
<p><strong>Iteration:</strong> Once you have identified the failure modes and prioritized them, you can start working on fixing them. After fixing them, you can go through the same process again to identify new failure modes that are still there. It‚Äôs very important to know that error analysis is an iterative process. You need to do it two or three times at first.</p>
</section>
<section id="scale-your-evals-in-production" class="level3">
<h3 class="anchored" data-anchor-id="scale-your-evals-in-production">Scale your evals in production</h3>
<p>You might ask yourself if you‚Äôll be doing this manually over production data to verify if th? The answer is that once you have a good understanding of the failure modes and have fixed the most critical ones, you can scale your evaluation by running a custom LLM-as-a-judge for large samples of queries that you have in prod.</p>
<p>Here‚Äôs how to do it: - Get the traces that you‚Äôve labeled previously with successful and failed queries &amp; split them into a train, a dev and a test set.</p>
<ul>
<li>Create a custom LLM-as-a-judge for each failure mode:
<ul>
<li>For each failure mode, create a prompt that describes the failure mode in a very specific way. Don‚Äôt be broad in your description and don‚Äôt use vague word (like good, etc). and provides examples of successful and failed queries from your labeled dataset.</li>
<li>Provide the LLM with example of both successful and failed queries from your train dataset to help it understand the failure mode better.</li>
<li>Eval the performance of the LLM-as-a-judge on your dev set and iterate on the prompt until you reach a satisfactory performance</li>
<li>Once you‚Äôre satisfied with the performance on the dev set, test the LLM-as-a-judge on your test set to get an estimate of its performance on unseen data. This should give you a good idea of how well the LLM-as-a-judge will perform on production data.</li>
</ul></li>
</ul>
<p>Now, this LLM-as-a-judge can be used to evaluate large samples of production queries and identify the failure modes that are still present in your system.</p>
</section>
</section>
<section id="sub-lesson-2-clustering-production-queries-didnt-work-for-me" class="level2">
<h2 class="anchored" data-anchor-id="sub-lesson-2-clustering-production-queries-didnt-work-for-me">Sub-lesson 2: Clustering production queries didn‚Äôt work for me</h2>
<p>One approach that I‚Äôve tested in the past (amounts to 1 year) and that didn‚Äôt work that well for me is to identify a set of classes that I expect user queries in my app to fall into. Identifying the classes helps in knowing which queries the model is not handling well and which classes of queries need more attention.</p>
<p>On top of the identified classes, I would create a category for ‚Äúother‚Äù queries that don‚Äôt fall into any of the identified classes. an analysis of the queries that have fallen into the ‚Äúother‚Äù category helped me identify new classes that I hadn‚Äôt thought about initially and better pinpoint the analysis of the performance of the model on different types of queries.</p>
<p>At the time, I used GPT-4 to do the classification. What didn‚Äôt work well for me was most queries ended up in the ‚Äúother‚Äù category, defeating the purpose of the classification. This pattern showed up with a couple of other decoder LLMs.</p>
<p>While I thought about finetuning a Bert-like model to do the classification, having to finetune a new model whenever a new class is identified seemed like an overkill and a maintenance nightmare.</p>
<div class="cell" data-fig-width="6" data-fig-height="8" data-layout-align="center">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<svg width="576" height="768" viewbox="0.00 0.00 217.75 488.00" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 484)">
<title>G</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-484 213.75,-484 213.75,4 -4,4"></polygon>
<!-- Start -->
<g id="node1" class="node">
<title>Start</title>
<path fill="#e6f3ff" stroke="#0066cc" stroke-width="2" d="M154.53,-480C154.53,-480 55.56,-480 55.56,-480 49.56,-480 43.56,-474 43.56,-468 43.56,-468 43.56,-456 43.56,-456 43.56,-450 49.56,-444 55.56,-444 55.56,-444 154.53,-444 154.53,-444 160.53,-444 166.53,-450 166.53,-456 166.53,-456 166.53,-468 166.53,-468 166.53,-474 160.53,-480 154.53,-480"></path>
<text text-anchor="middle" x="105.05" y="-465.3" font-family="Arial" font-size="11.00">Define Query Classes</text>
<text text-anchor="middle" x="105.05" y="-452.1" font-family="Arial" font-size="11.00">+ 'Other' Category</text>
</g>
<!-- Classify -->
<g id="node2" class="node">
<title>Classify</title>
<polygon fill="#fff9e6" stroke="black" points="105.05,-406.9 24.44,-372.6 105.05,-338.3 185.65,-372.6 105.05,-406.9"></polygon>
<text text-anchor="middle" x="105.05" y="-375.9" font-family="Arial" font-size="11.00">GPT-4</text>
<text text-anchor="middle" x="105.05" y="-362.7" font-family="Arial" font-size="11.00">Classification</text>
</g>
<!-- Start&#45;&gt;Classify -->
<g id="edge1" class="edge">
<title>Start-&gt;Classify</title>
<path fill="none" stroke="black" d="M105.05,-443.73C105.05,-436.06 105.05,-426.65 105.05,-417.24"></path>
<polygon fill="black" stroke="black" points="108.55,-417.11 105.05,-407.11 101.55,-417.11 108.55,-417.11"></polygon>
</g>
<!-- ToClass -->
<g id="node3" class="node">
<title>ToClass</title>
<path fill="none" stroke="black" d="M84.14,-291.4C84.14,-291.4 11.95,-291.4 11.95,-291.4 5.95,-291.4 -0.05,-285.4 -0.05,-279.4 -0.05,-279.4 -0.05,-267.4 -0.05,-267.4 -0.05,-261.4 5.95,-255.4 11.95,-255.4 11.95,-255.4 84.14,-255.4 84.14,-255.4 90.14,-255.4 96.14,-261.4 96.14,-267.4 96.14,-267.4 96.14,-279.4 96.14,-279.4 96.14,-285.4 90.14,-291.4 84.14,-291.4"></path>
<text text-anchor="middle" x="48.05" y="-276.7" font-family="Arial" font-size="11.00">Few Queries:</text>
<text text-anchor="middle" x="48.05" y="-263.5" font-family="Arial" font-size="11.00">Defined Classes</text>
</g>
<!-- Classify&#45;&gt;ToClass -->
<g id="edge2" class="edge">
<title>Classify-&gt;ToClass</title>
<path fill="none" stroke="black" d="M89.32,-344.78C81.23,-330.99 71.42,-314.26 63.39,-300.56"></path>
<polygon fill="black" stroke="black" points="66.24,-298.5 58.16,-291.64 60.2,-302.04 66.24,-298.5"></polygon>
<text text-anchor="middle" x="83.55" y="-312.1" font-family="Arial" font-size="9.00">Few</text>
</g>
<!-- ToOther -->
<g id="node4" class="node">
<title>ToOther</title>
<path fill="#ffe6e6" stroke="#ff6666" stroke-width="2" d="M197.95,-291.4C197.95,-291.4 126.15,-291.4 126.15,-291.4 120.15,-291.4 114.15,-285.4 114.15,-279.4 114.15,-279.4 114.15,-267.4 114.15,-267.4 114.15,-261.4 120.15,-255.4 126.15,-255.4 126.15,-255.4 197.95,-255.4 197.95,-255.4 203.95,-255.4 209.95,-261.4 209.95,-267.4 209.95,-267.4 209.95,-279.4 209.95,-279.4 209.95,-285.4 203.95,-291.4 197.95,-291.4"></path>
<text text-anchor="middle" x="162.05" y="-276.7" font-family="Arial" font-size="11.00">Most Queries:</text>
<text text-anchor="middle" x="162.05" y="-263.5" font-family="Arial" font-size="11.00">'Other' Category</text>
</g>
<!-- Classify&#45;&gt;ToOther -->
<g id="edge3" class="edge">
<title>Classify-&gt;ToOther</title>
<path fill="none" stroke="black" stroke-width="2" d="M120.77,-344.78C128.86,-330.99 138.67,-314.26 146.7,-300.56"></path>
<polygon fill="black" stroke="black" stroke-width="2" points="149.9,-302.04 151.93,-291.64 143.86,-298.5 149.9,-302.04"></polygon>
<text text-anchor="middle" x="149.8" y="-312.1" font-family="Arial" font-size="9.00">Most</text>
</g>
<!-- Problem -->
<g id="node5" class="node">
<title>Problem</title>
<polygon fill="#ffcccc" stroke="#ff0000" stroke-width="3" points="166.9,-218.2 41.19,-218.2 41.19,-171 166.9,-171 166.9,-218.2"></polygon>
<text text-anchor="middle" x="104.05" y="-204.5" font-family="Arial" font-size="11.00">‚ö†Ô∏è PROBLEM:</text>
<text text-anchor="middle" x="104.05" y="-191.3" font-family="Arial" font-size="11.00">Most queries in 'Other'</text>
<text text-anchor="middle" x="104.05" y="-178.1" font-family="Arial" font-size="11.00">Defeats Purpose!</text>
</g>
<!-- ToClass&#45;&gt;Problem -->
<g id="edge4" class="edge">
<title>ToClass-&gt;Problem</title>
<path fill="none" stroke="black" d="M60.48,-255.36C66.61,-246.95 74.2,-236.54 81.32,-226.77"></path>
<polygon fill="black" stroke="black" points="84.34,-228.57 87.4,-218.42 78.68,-224.44 84.34,-228.57"></polygon>
</g>
<!-- ToOther&#45;&gt;Problem -->
<g id="edge5" class="edge">
<title>ToOther-&gt;Problem</title>
<path fill="none" stroke="black" stroke-width="2" d="M149.17,-255.36C142.76,-246.86 134.8,-236.33 127.37,-226.48"></path>
<polygon fill="black" stroke="black" stroke-width="2" points="130.1,-224.3 121.28,-218.42 124.52,-228.51 130.1,-224.3"></polygon>
</g>
<!-- ConsiderBERT -->
<g id="node6" class="node">
<title>ConsiderBERT</title>
<path fill="none" stroke="black" d="M129.04,-133.8C129.04,-133.8 79.06,-133.8 79.06,-133.8 73.06,-133.8 67.06,-127.8 67.06,-121.8 67.06,-121.8 67.06,-109.8 67.06,-109.8 67.06,-103.8 73.06,-97.8 79.06,-97.8 79.06,-97.8 129.04,-97.8 129.04,-97.8 135.04,-97.8 141.04,-103.8 141.04,-109.8 141.04,-109.8 141.04,-121.8 141.04,-121.8 141.04,-127.8 135.04,-133.8 129.04,-133.8"></path>
<text text-anchor="middle" x="104.05" y="-119.1" font-family="Arial" font-size="11.00">Try BERT</text>
<text text-anchor="middle" x="104.05" y="-105.9" font-family="Arial" font-size="11.00">Finetuning?</text>
</g>
<!-- Problem&#45;&gt;ConsiderBERT -->
<g id="edge6" class="edge">
<title>Problem-&gt;ConsiderBERT</title>
<path fill="none" stroke="black" d="M104.05,-170.97C104.05,-162.54 104.05,-152.88 104.05,-144.08"></path>
<polygon fill="black" stroke="black" points="107.55,-143.9 104.05,-133.9 100.55,-143.9 107.55,-143.9"></polygon>
</g>
<!-- Problem2 -->
<g id="node7" class="node">
<title>Problem2</title>
<polygon fill="#ffcccc" stroke="#ff0000" stroke-width="3" points="171.89,-60.7 36.21,-60.7 36.21,-0.1 171.89,-0.1 171.89,-60.7"></polygon>
<text text-anchor="middle" x="104.05" y="-46.9" font-family="Arial" font-size="11.00">‚ö†Ô∏è PROBLEM:</text>
<text text-anchor="middle" x="104.05" y="-33.7" font-family="Arial" font-size="11.00">Must retrain for</text>
<text text-anchor="middle" x="104.05" y="-20.5" font-family="Arial" font-size="11.00">each new class</text>
<text text-anchor="middle" x="104.05" y="-7.3" font-family="Arial" font-size="11.00">Maintenance Nightmare!</text>
</g>
<!-- ConsiderBERT&#45;&gt;Problem2 -->
<g id="edge7" class="edge">
<title>ConsiderBERT-&gt;Problem2</title>
<path fill="none" stroke="black" d="M104.05,-97.52C104.05,-89.74 104.05,-80.21 104.05,-70.84"></path>
<polygon fill="black" stroke="black" points="107.55,-70.81 104.05,-60.81 100.55,-70.81 107.55,-70.81"></polygon>
</g>
</g>
</svg>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</section>
</section>
<section id="lesson-4-off-the-shelf-evals-dont-work-that-well" class="level1">
<h1>Lesson 4: Off-the-shelf evals don‚Äôt work that well</h1>
<p>Off-the shelf evals don‚Äôt work that well. In the different frameworks/vendors interfaces for LLM applications evaluation, you‚Äôll stumble upon two kinds of metrics:</p>
<ul>
<li><p><strong>LLM-based metrics:</strong> These metrics use an LLM to evaluate the quality of the output based on some criteria (e.g., relevance, coherence, etc.). While these metrics can be useful, the prompt used in them is generic and not at all tailored to your specific application and its requirements. Think of LLM-as-a-judge for a second. Usually, you would want the judge to have ample context about your application and the specific criterion you want to evaluate. A generic prompt won‚Äôt cut it at all. The same goes for the metrics that are LLM-based.</p></li>
<li><p><strong>Non-LLM-based metrics:</strong> These metrics are usually quite generic (e.g., BLEU, ROUGE, etc.) and don‚Äôt capture how well your application is performing on a business standpoint.</p></li>
</ul>
<p>In this <a href="https://docs.ragas.io/en/latest/concepts/metrics/available_metrics/#agents-or-tool-use-cases">page</a>, you can find many examples of both families of metrics.</p>
<p>Thse non-custom metrics will tell you if your system is so bad but can‚Äôt be used that much for <strong>incremental improvements</strong>. Many times, I‚Äôve seen that incremental improvements have as much impact on the LLM-based metrics as just rerunning your code with the same prompt and the same settings.</p>
<p>Now, all the vendors I‚Äôve worked with allow you to create custom metrics (usually called <code>scorer</code>). So, you can use some vendor API to create your own custom metric in code and have it integrated in their evaluation interface.</p>
</section>
<section id="lesson-5-the-evaluation-interface-matters" class="level1">
<h1>Lesson 5: The evaluation interface matters</h1>
<p>When using an interface to evaluate your LLM applications, the interface matters a lot. A good interface should in general empower you to spot the failure modes and annotate your data easily.</p>
<p>I‚Äôve worked with many vendors providing LLM evaluation interfaces for LLM applications. Their interfaces are quite similar and are actually pretty good to hit the ground running. They will allow you to go through the traces of your LLM applications, see the inputs and outputs, and annotate them with a few clicks. However, what I usually find lacking is the following:</p>
<ul>
<li><p>One pattern that slows me most is not having a specific field for failure mode annotation. The slowing down appears most when for example some failure modes have already appeared in the data but I‚Äôll have to write them down again and again for each new trace that I see. Having a specific field for failure mode annotation or just the most recurrent failure modes as options to select from would speed up the annotation process a lot.</p></li>
<li><p>Formatting üíÑ is not customizable: Imagine you have an app for writing emails. When doing your error analysis, you want to see the email formatted as it would appear in an email client (with subject, greeting, body, signature, etc.). This will allow you to easily spot the failure modes instead of having to look at a JSON or a plain blob of text (which is the case of all the interfaces I know). The absence of appropriate formatting slows down the error analysis process a lot.</p></li>
</ul>
<p>If you want to know more about this topic, I recommend you read <a href="https://chrislovejoy.me/llm-native-expert-system">this talk</a> I wrote by Christopher Lovejoy on building LLM-native apps in vertical industries.</p>
</section>
<section id="final-notes" class="level1">
<h1>Final notes</h1>
<ul>
<li><p>Don‚Äôt hesitate to reach out to me on <a href="https://www.linkedin.com/in/chsafouane/">LinkedIn</a> or via email (chsafouane@gmail.com) if you‚Äôd like to talk about this topic or if you have any questions. My company <a href="https://www.linkedin.com/company/lumiereai/">Lumiereai</a> also offers consulting services on this topic.</p></li>
<li><p>This blog post is not exhaustive. Just before publishing it, I‚Äôve noticed that Hamel Husain has published a very extensive <a href="https://hamel.dev/blog/posts/evals-faq/">blog post</a> on the same topic with many more lessons learnt. I highly recommend you read it as well. He‚Äôs the most knowledgeable person I know on this topic and I‚Äôve learnt a lot from his work.</p></li>
<li><p>I wasn‚Äôt paid at all to say this and this is a really a personal advice: If you have the money or your company can pay for it, I really advise you to take Hamel &amp; Shreya‚Äôs <a href="https://maven.com/parlance-labs/evals">course</a> on LLM evals. It‚Äôs worth every penny and will save you a lot of time and effort in the long run. Otherwise, there is an upcoming book on the same topic that they are writing with Oreilly. Keep an eye on it.</p></li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "Óßã";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/chsafouane\.github\.io");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>